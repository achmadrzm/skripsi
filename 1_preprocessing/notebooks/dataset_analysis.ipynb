{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1381c2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ©º MIT-BIH AF Dataset Analysis Tool\n",
      "ðŸ“‹ Analyzing dataset composition and single-annotation record impact\n",
      "\n",
      "============================================================\n",
      "         DATASET COMPOSITION ANALYSIS\n",
      "============================================================\n",
      "Scanning for records in: D:\\skripsi_teknis\\dataset\\mitbih-afdb\n",
      "âœ… Found 23 complete records\n",
      "\n",
      "ðŸ” Analyzing 23 records...\n",
      "  [ 1/23] Analyzing 04015... âœ“ Multi-annotation (2 labels)\n",
      "  [ 2/23] Analyzing 04043... âœ“ Multi-annotation (3 labels)\n",
      "  [ 3/23] Analyzing 04048... âœ“ Multi-annotation (2 labels)\n",
      "  [ 4/23] Analyzing 04126... âœ“ Multi-annotation (2 labels)\n",
      "  [ 5/23] Analyzing 04746... âœ“ Multi-annotation (2 labels)\n",
      "  [ 6/23] Analyzing 04908... âœ“ Multi-annotation (3 labels)\n",
      "  [ 7/23] Analyzing 04936... âœ“ Multi-annotation (3 labels)\n",
      "  [ 8/23] Analyzing 05091... âœ“ Multi-annotation (2 labels)\n",
      "  [ 9/23] Analyzing 05121... âœ“ Multi-annotation (3 labels)\n",
      "  [10/23] Analyzing 05261... âœ“ Multi-annotation (2 labels)\n",
      "  [11/23] Analyzing 06426... âœ“ Multi-annotation (4 labels)\n",
      "  [12/23] Analyzing 06453... âœ“ Multi-annotation (2 labels)\n",
      "  [13/23] Analyzing 06995... âœ“ Multi-annotation (3 labels)\n",
      "  [14/23] Analyzing 07162... âœ“ Single-annotation ((AFIB)\n",
      "  [15/23] Analyzing 07859... âœ“ Single-annotation ((AFIB)\n",
      "  [16/23] Analyzing 07879... âœ“ Multi-annotation (3 labels)\n",
      "  [17/23] Analyzing 07910... âœ“ Multi-annotation (3 labels)\n",
      "  [18/23] Analyzing 08215... âœ“ Multi-annotation (3 labels)\n",
      "  [19/23] Analyzing 08219... âœ“ Multi-annotation (2 labels)\n",
      "  [20/23] Analyzing 08378... âœ“ Multi-annotation (3 labels)\n",
      "  [21/23] Analyzing 08405... âœ“ Multi-annotation (2 labels)\n",
      "  [22/23] Analyzing 08434... âœ“ Multi-annotation (2 labels)\n",
      "  [23/23] Analyzing 08455... âœ“ Multi-annotation (2 labels)\n",
      "\n",
      "============================================================\n",
      "                    SUMMARY\n",
      "============================================================\n",
      "ðŸ“Š Dataset Overview:\n",
      "   Total records found: 23\n",
      "   Successfully analyzed: 23\n",
      "   Failed to analyze: 0\n",
      "\n",
      "ðŸ“ˆ Record Types:\n",
      "   Single-annotation records: 2\n",
      "   Multi-annotation records: 21\n",
      "\n",
      "ðŸ” Single-Annotation Records Detail:\n",
      "   AF-only records: 2\n",
      "   Normal-only records: 0\n",
      "   Other-only records: 0\n",
      "   Total windows from single-annotation: 14,726\n",
      "     AF windows: 14,726\n",
      "     Normal windows: 0\n",
      "\n",
      "   Individual Record Details:\n",
      "     07162: (AFIB    (7,363 windows,  10.2h)\n",
      "     07859: (AFIB    (7,363 windows,  10.2h)\n",
      "\n",
      "ðŸ” Multi-Annotation Records Detail:\n",
      "   Total windows from multi-annotation: 153,919\n",
      "\n",
      "   Individual Record Details:\n",
      "     04015: (AFIB, (N            (7,363 windows,  10.2h)\n",
      "     04043: (AFIB, (AFL, (N      (7,363 windows,  10.2h)\n",
      "     04048: (AFIB, (N            (7,363 windows,  10.2h)\n",
      "     04126: (AFIB, (N            (7,363 windows,  10.2h)\n",
      "     04746: (AFIB, (N            (7,363 windows,  10.2h)\n",
      "     04908: (AFIB, (AFL, (N      (7,363 windows,  10.2h)\n",
      "     04936: (AFIB, (AFL, (N      (7,363 windows,  10.2h)\n",
      "     05091: (AFIB, (N            (7,363 windows,  10.2h)\n",
      "     05121: (AFIB, (J, (N        (7,363 windows,  10.2h)\n",
      "     05261: (AFIB, (N            (7,363 windows,  10.2h)\n",
      "     06426: (AFIB, (AFL, (J, (N  (7,363 windows,  10.2h)\n",
      "     06995: (AFIB, (AFL, (N      (7,363 windows,  10.2h)\n",
      "     07879: (AFIB, (J, (N        (7,363 windows,  10.2h)\n",
      "     07910: (AFIB, (AFL, (N      (7,363 windows,  10.2h)\n",
      "     08215: (AFIB, (AFL, (N      (7,363 windows,  10.2h)\n",
      "     08219: (AFIB, (N            (7,363 windows,  10.2h)\n",
      "     08378: (AFIB, (AFL, (N      (7,363 windows,  10.2h)\n",
      "     08405: (AFIB, (N            (7,363 windows,  10.2h)\n",
      "     08434: (AFIB, (N            (7,363 windows,  10.2h)\n",
      "     08455: (AFIB, (N            (7,363 windows,  10.2h)\n",
      "     06453: (AFIB, (N            (6,659 windows,   9.2h)\n",
      "\n",
      "ðŸ“Š Impact Analysis:\n",
      "   Total estimated windows: 168,645\n",
      "   From single-annotation: 14,726 (8.7%)\n",
      "   From multi-annotation: 153,919 (91.3%)\n",
      "\n",
      "============================================================\n",
      "              INCLUSION DECISION ANALYSIS\n",
      "============================================================\n",
      "ðŸ“Š Key Metrics:\n",
      "   Total records: 23\n",
      "   Single-annotation contribution: 8.7% of total windows\n",
      "   Max single record contribution: 4.4%\n",
      "   AF-only records: 2\n",
      "   Normal-only records: 0\n",
      "\n",
      "âœ… Benefits of Including Single-Annotation Records:\n",
      "   1. Medium dataset (23 records) - additional data helpful\n",
      "   2. Reasonable single-annotation contribution (8.7%)\n",
      "   3. No single record dominance (4.4%)\n",
      "\n",
      "âš ï¸  Potential Risks/Concerns:\n",
      "   1. Only one class in single-annotation records\n",
      "\n",
      "ðŸŽ¯ DECISION ANALYSIS:\n",
      "   Benefits: 3\n",
      "   Risks: 1\n",
      "   Warnings: 0\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ FINAL RECOMMENDATION: âœ… INCLUDE single-annotation records\n",
      "ðŸ“ Reasoning: Benefits clearly outweigh risks\n",
      "============================================================\n",
      "\n",
      "ðŸ’¾ Saving analysis results...\n",
      "âœ… Results saved to: D:\\skripsi_teknis\\dataset\\dataset_analysis_results.csv\n",
      "ðŸ“‹ Decision: include\n",
      "\n",
      "ðŸŽ‰ Analysis complete!\n",
      "ðŸ“„ Check the CSV file for detailed results.\n",
      "ðŸ’¡ Use this analysis to inform your preprocessing decisions.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dataset Analysis Script untuk MIT-BIH AF Dataset\n",
    "Menganalisis komposisi dataset dan memberikan rekomendasi untuk single-annotation records\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Configuration - SESUAIKAN dengan path Anda\n",
    "DATA_DIR = 'D:\\\\skripsi_teknis\\\\dataset\\\\mitbih-afdb'\n",
    "\n",
    "def get_available_records():\n",
    "    \"\"\"\n",
    "    Get list of available MIT-BIH AF records dari path lokal\n",
    "    \"\"\"\n",
    "    print(f\"Scanning for records in: {DATA_DIR}\")\n",
    "    \n",
    "    # Cari file .dat untuk mendapatkan record IDs yang tersedia\n",
    "    dat_files = glob.glob(os.path.join(DATA_DIR, \"*.dat\"))\n",
    "    \n",
    "    if not dat_files:\n",
    "        print(f\"âŒ No .dat files found in {DATA_DIR}\")\n",
    "        print(\"Please check your DATA_DIR path!\")\n",
    "        return []\n",
    "    \n",
    "    available_records = []\n",
    "    for dat_file in dat_files:\n",
    "        # Extract record ID dari nama file (contoh: 04015.dat -> 04015)\n",
    "        record_id = os.path.splitext(os.path.basename(dat_file))[0]\n",
    "        \n",
    "        # Pastikan file annotation (.atr) juga tersedia\n",
    "        atr_file = os.path.join(DATA_DIR, f\"{record_id}.atr\")\n",
    "        hea_file = os.path.join(DATA_DIR, f\"{record_id}.hea\")\n",
    "        \n",
    "        if os.path.exists(atr_file) and os.path.exists(hea_file):\n",
    "            available_records.append(record_id)\n",
    "        else:\n",
    "            print(f\"âš ï¸ Missing annotation or header file for {record_id}\")\n",
    "    \n",
    "    print(f\"âœ… Found {len(available_records)} complete records\")\n",
    "    return sorted(available_records)\n",
    "\n",
    "def analyze_single_record(record_id):\n",
    "    \"\"\"\n",
    "    Analisis detail untuk satu record\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load record dan annotation\n",
    "        record_path = os.path.join(DATA_DIR, record_id)\n",
    "        record = wfdb.rdrecord(record_path)\n",
    "        ann = wfdb.rdann(record_path, \"atr\")\n",
    "        \n",
    "        # Basic info\n",
    "        fs = record.fs\n",
    "        duration_sec = record.sig_len / fs\n",
    "        duration_hours = duration_sec / 3600\n",
    "        \n",
    "        # Annotation analysis\n",
    "        if hasattr(ann, 'aux_note') and ann.aux_note is not None:\n",
    "            labels = [label.strip() for label in ann.aux_note]\n",
    "            unique_labels = set(labels)\n",
    "            \n",
    "            # Estimate windows (10-second windows with 50% overlap)\n",
    "            estimated_windows = int((duration_sec / 10) * 2 - 1)  # Rough estimate with overlap\n",
    "            \n",
    "            # Classify AF vs Normal labels\n",
    "            af_labels = {'(AFIB', 'AFIB'}\n",
    "            normal_labels = {'(N', 'N', 'NSR'}\n",
    "            \n",
    "            af_annotations = [label for label in labels if label in af_labels]\n",
    "            normal_annotations = [label for label in labels if label in normal_labels]\n",
    "            other_annotations = [label for label in labels if label not in af_labels and label not in normal_labels]\n",
    "            \n",
    "            return {\n",
    "                'record_id': record_id,\n",
    "                'duration_hours': duration_hours,\n",
    "                'duration_sec': duration_sec,\n",
    "                'sampling_rate': fs,\n",
    "                'total_annotations': len(labels),\n",
    "                'unique_labels': unique_labels,\n",
    "                'af_annotation_count': len(af_annotations),\n",
    "                'normal_annotation_count': len(normal_annotations),\n",
    "                'other_annotation_count': len(other_annotations),\n",
    "                'estimated_windows': estimated_windows,\n",
    "                'is_single_annotation': len(unique_labels) == 1,\n",
    "                'predominant_rhythm': list(unique_labels)[0] if len(unique_labels) == 1 else 'Mixed',\n",
    "                'all_labels': labels\n",
    "            }\n",
    "        else:\n",
    "            print(f\"âš ï¸ No annotations found for {record_id}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error analyzing {record_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_dataset_composition():\n",
    "    \"\"\"\n",
    "    Analisis komposisi dataset lengkap\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"         DATASET COMPOSITION ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    records = get_available_records()\n",
    "    \n",
    "    if not records:\n",
    "        print(\"âŒ No records found. Please check your DATA_DIR path.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Analyze each record\n",
    "    all_analyses = []\n",
    "    single_annotation_records = []\n",
    "    multi_annotation_records = []\n",
    "    failed_records = []\n",
    "    \n",
    "    print(f\"\\nðŸ” Analyzing {len(records)} records...\")\n",
    "    \n",
    "    for i, record_id in enumerate(records, 1):\n",
    "        print(f\"  [{i:2d}/{len(records)}] Analyzing {record_id}...\", end=\" \")\n",
    "        \n",
    "        analysis = analyze_single_record(record_id)\n",
    "        \n",
    "        if analysis:\n",
    "            all_analyses.append(analysis)\n",
    "            \n",
    "            if analysis['is_single_annotation']:\n",
    "                single_annotation_records.append(analysis)\n",
    "                print(f\"âœ“ Single-annotation ({analysis['predominant_rhythm']})\")\n",
    "            else:\n",
    "                multi_annotation_records.append(analysis)\n",
    "                print(f\"âœ“ Multi-annotation ({len(analysis['unique_labels'])} labels)\")\n",
    "        else:\n",
    "            failed_records.append(record_id)\n",
    "            print(\"âŒ Failed\")\n",
    "    \n",
    "    # Summary Statistics\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"                    SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"ðŸ“Š Dataset Overview:\")\n",
    "    print(f\"   Total records found: {len(records)}\")\n",
    "    print(f\"   Successfully analyzed: {len(all_analyses)}\")\n",
    "    print(f\"   Failed to analyze: {len(failed_records)}\")\n",
    "    \n",
    "    if failed_records:\n",
    "        print(f\"   Failed records: {failed_records}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Record Types:\")\n",
    "    print(f\"   Single-annotation records: {len(single_annotation_records)}\")\n",
    "    print(f\"   Multi-annotation records: {len(multi_annotation_records)}\")\n",
    "    \n",
    "    # Detailed breakdown\n",
    "    if single_annotation_records:\n",
    "        print(f\"\\nðŸ” Single-Annotation Records Detail:\")\n",
    "        \n",
    "        af_single = [r for r in single_annotation_records if r['predominant_rhythm'] in ['(AFIB', 'AFIB']]\n",
    "        normal_single = [r for r in single_annotation_records if r['predominant_rhythm'] in ['(N', 'N', 'NSR']]\n",
    "        other_single = [r for r in single_annotation_records if r not in af_single and r not in normal_single]\n",
    "        \n",
    "        print(f\"   AF-only records: {len(af_single)}\")\n",
    "        print(f\"   Normal-only records: {len(normal_single)}\")\n",
    "        print(f\"   Other-only records: {len(other_single)}\")\n",
    "        \n",
    "        total_single_windows = sum(r['estimated_windows'] for r in single_annotation_records)\n",
    "        af_single_windows = sum(r['estimated_windows'] for r in af_single)\n",
    "        normal_single_windows = sum(r['estimated_windows'] for r in normal_single)\n",
    "        \n",
    "        print(f\"   Total windows from single-annotation: {total_single_windows:,}\")\n",
    "        print(f\"     AF windows: {af_single_windows:,}\")\n",
    "        print(f\"     Normal windows: {normal_single_windows:,}\")\n",
    "        \n",
    "        print(f\"\\n   Individual Record Details:\")\n",
    "        for record in sorted(single_annotation_records, key=lambda x: x['estimated_windows'], reverse=True):\n",
    "            print(f\"     {record['record_id']}: {record['predominant_rhythm']:8s} \"\n",
    "                  f\"({record['estimated_windows']:4,} windows, {record['duration_hours']:5.1f}h)\")\n",
    "    \n",
    "    if multi_annotation_records:\n",
    "        print(f\"\\nðŸ” Multi-Annotation Records Detail:\")\n",
    "        \n",
    "        total_multi_windows = sum(r['estimated_windows'] for r in multi_annotation_records)\n",
    "        print(f\"   Total windows from multi-annotation: {total_multi_windows:,}\")\n",
    "        \n",
    "        print(f\"\\n   Individual Record Details:\")\n",
    "        for record in sorted(multi_annotation_records, key=lambda x: x['estimated_windows'], reverse=True):\n",
    "            labels_str = ', '.join(sorted(record['unique_labels']))\n",
    "            print(f\"     {record['record_id']}: {labels_str:20s} \"\n",
    "                  f\"({record['estimated_windows']:4,} windows, {record['duration_hours']:5.1f}h)\")\n",
    "    \n",
    "    # Impact Analysis\n",
    "    if single_annotation_records and multi_annotation_records:\n",
    "        single_windows = sum(r['estimated_windows'] for r in single_annotation_records)\n",
    "        multi_windows = sum(r['estimated_windows'] for r in multi_annotation_records)\n",
    "        total_windows = single_windows + multi_windows\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Impact Analysis:\")\n",
    "        print(f\"   Total estimated windows: {total_windows:,}\")\n",
    "        print(f\"   From single-annotation: {single_windows:,} ({single_windows/total_windows:.1%})\")\n",
    "        print(f\"   From multi-annotation: {multi_windows:,} ({multi_windows/total_windows:.1%})\")\n",
    "        \n",
    "        # Check for dominant records\n",
    "        if single_annotation_records:\n",
    "            max_single_windows = max(r['estimated_windows'] for r in single_annotation_records)\n",
    "            max_contribution = max_single_windows / total_windows\n",
    "            \n",
    "            if max_contribution > 0.3:\n",
    "                print(f\"   âš ï¸  WARNING: One single-annotation record contributes {max_contribution:.1%} of total windows\")\n",
    "            \n",
    "    return single_annotation_records, multi_annotation_records\n",
    "\n",
    "def make_inclusion_decision(single_records, multi_records):\n",
    "    \"\"\"\n",
    "    Automated decision berdasarkan dataset characteristics\n",
    "    \"\"\"\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"              INCLUSION DECISION ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not single_records:\n",
    "        print(\"âŒ No single-annotation records found.\")\n",
    "        print(\"ðŸŽ¯ DECISION: N/A (no single-annotation records to include/exclude)\")\n",
    "        return \"no_single_records\"\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_records = len(single_records) + len(multi_records)\n",
    "    \n",
    "    single_windows = sum(r['estimated_windows'] for r in single_records)\n",
    "    multi_windows = sum(r['estimated_windows'] for r in multi_records) if multi_records else 0\n",
    "    total_windows = single_windows + multi_windows\n",
    "    \n",
    "    single_ratio = single_windows / total_windows if total_windows > 0 else 0\n",
    "    \n",
    "    # Check class distribution\n",
    "    af_single = [r for r in single_records if r['predominant_rhythm'] in ['(AFIB', 'AFIB']]\n",
    "    normal_single = [r for r in single_records if r['predominant_rhythm'] in ['(N', 'N', 'NSR']]\n",
    "    \n",
    "    # Check for extreme records\n",
    "    max_windows_per_record = max(r['estimated_windows'] for r in single_records)\n",
    "    max_contribution = max_windows_per_record / total_windows if total_windows > 0 else 0\n",
    "    \n",
    "    # Decision logic\n",
    "    risk_factors = []\n",
    "    benefits = []\n",
    "    warnings = []\n",
    "    \n",
    "    print(f\"ðŸ“Š Key Metrics:\")\n",
    "    print(f\"   Total records: {total_records}\")\n",
    "    print(f\"   Single-annotation contribution: {single_ratio:.1%} of total windows\")\n",
    "    print(f\"   Max single record contribution: {max_contribution:.1%}\")\n",
    "    print(f\"   AF-only records: {len(af_single)}\")\n",
    "    print(f\"   Normal-only records: {len(normal_single)}\")\n",
    "    \n",
    "    # Dataset size factor\n",
    "    if total_records < 15:\n",
    "        benefits.append(f\"Small dataset ({total_records} records) - every record valuable\")\n",
    "    elif total_records > 25:\n",
    "        risk_factors.append(f\"Large dataset ({total_records} records) - single-annotation not essential\")\n",
    "    else:\n",
    "        benefits.append(f\"Medium dataset ({total_records} records) - additional data helpful\")\n",
    "    \n",
    "    # Contribution factor  \n",
    "    if single_ratio > 0.6:\n",
    "        risk_factors.append(f\"Very high single-annotation contribution ({single_ratio:.1%})\")\n",
    "    elif single_ratio > 0.4:\n",
    "        warnings.append(f\"High single-annotation contribution ({single_ratio:.1%}) - consider limits\")\n",
    "    elif single_ratio < 0.3:\n",
    "        benefits.append(f\"Reasonable single-annotation contribution ({single_ratio:.1%})\")\n",
    "    \n",
    "    # Balance factor\n",
    "    if len(af_single) > 0 and len(normal_single) > 0:\n",
    "        benefits.append(\"Both AF and Normal single-annotation records available\")\n",
    "        af_single_windows = sum(r['estimated_windows'] for r in af_single)\n",
    "        normal_single_windows = sum(r['estimated_windows'] for r in normal_single)\n",
    "        af_ratio = af_single_windows / (af_single_windows + normal_single_windows)\n",
    "        \n",
    "        if 0.3 <= af_ratio <= 0.7:\n",
    "            benefits.append(f\"Balanced AF/Normal ratio in single-annotation ({af_ratio:.1%} AF)\")\n",
    "        else:\n",
    "            warnings.append(f\"Imbalanced AF/Normal in single-annotation ({af_ratio:.1%} AF)\")\n",
    "    else:\n",
    "        risk_factors.append(\"Only one class in single-annotation records\")\n",
    "    \n",
    "    # Dominance factor\n",
    "    if max_contribution > 0.5:\n",
    "        risk_factors.append(f\"One record dominates dataset ({max_contribution:.1%})\")\n",
    "    elif max_contribution > 0.3:\n",
    "        warnings.append(f\"One record has high contribution ({max_contribution:.1%})\")\n",
    "    elif max_contribution < 0.2:\n",
    "        benefits.append(f\"No single record dominance ({max_contribution:.1%})\")\n",
    "    \n",
    "    # Present analysis\n",
    "    print(f\"\\nâœ… Benefits of Including Single-Annotation Records:\")\n",
    "    if benefits:\n",
    "        for i, benefit in enumerate(benefits, 1):\n",
    "            print(f\"   {i}. {benefit}\")\n",
    "    else:\n",
    "        print(\"   None identified\")\n",
    "    \n",
    "    print(f\"\\nâš ï¸  Potential Risks/Concerns:\")\n",
    "    if risk_factors:\n",
    "        for i, risk in enumerate(risk_factors, 1):\n",
    "            print(f\"   {i}. {risk}\")\n",
    "    else:\n",
    "        print(\"   No major risks identified\")\n",
    "    \n",
    "    if warnings:\n",
    "        print(f\"\\nðŸŸ¡ Warnings (manageable with proper handling):\")\n",
    "        for i, warning in enumerate(warnings, 1):\n",
    "            print(f\"   {i}. {warning}\")\n",
    "    \n",
    "    # Final decision\n",
    "    risk_score = len(risk_factors)\n",
    "    benefit_score = len(benefits)\n",
    "    warning_score = len(warnings)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ DECISION ANALYSIS:\")\n",
    "    print(f\"   Benefits: {benefit_score}\")\n",
    "    print(f\"   Risks: {risk_score}\")\n",
    "    print(f\"   Warnings: {warning_score}\")\n",
    "    \n",
    "    if risk_score > benefit_score + 1:\n",
    "        decision = \"exclude\"\n",
    "        recommendation = \"âŒ EXCLUDE single-annotation records\"\n",
    "        reasoning = \"Significant risks outweigh benefits\"\n",
    "    elif benefit_score > risk_score and warning_score <= 1:\n",
    "        decision = \"include\"\n",
    "        recommendation = \"âœ… INCLUDE single-annotation records\"\n",
    "        reasoning = \"Benefits clearly outweigh risks\"\n",
    "    else:\n",
    "        decision = \"include_with_limits\"\n",
    "        recommendation = \"ðŸ›¡ï¸ INCLUDE with sampling limits\"\n",
    "        reasoning = \"Benefits present but need risk mitigation\"\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸŽ¯ FINAL RECOMMENDATION: {recommendation}\")\n",
    "    print(f\"ðŸ“ Reasoning: {reasoning}\")\n",
    "    \n",
    "    if decision == \"include_with_limits\":\n",
    "        print(f\"\\nðŸ’¡ Suggested Limits:\")\n",
    "        suggested_limit = min(2000, int(total_windows * 0.15 / len(single_records)))\n",
    "        print(f\"   - Max windows per single-annotation record: {suggested_limit}\")\n",
    "        print(f\"   - Max total contribution from single-annotation: 35%\")\n",
    "        print(f\"   - Apply random sampling if records exceed limits\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return decision\n",
    "\n",
    "def save_analysis_results(single_records, multi_records, decision):\n",
    "    \"\"\"\n",
    "    Save analysis results to CSV for reference\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ’¾ Saving analysis results...\")\n",
    "    \n",
    "    # Combine all records for CSV\n",
    "    all_records_data = []\n",
    "    \n",
    "    for record in single_records + multi_records:\n",
    "        all_records_data.append({\n",
    "            'record_id': record['record_id'],\n",
    "            'type': 'single_annotation' if record['is_single_annotation'] else 'multi_annotation',\n",
    "            'predominant_rhythm': record['predominant_rhythm'],\n",
    "            'unique_labels': ', '.join(sorted(record['unique_labels'])),\n",
    "            'duration_hours': record['duration_hours'],\n",
    "            'estimated_windows': record['estimated_windows'],\n",
    "            'total_annotations': record['total_annotations']\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(all_records_data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = os.path.join(os.path.dirname(DATA_DIR), 'dataset_analysis_results.csv')\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"âœ… Results saved to: {output_file}\")\n",
    "    print(f\"ðŸ“‹ Decision: {decision}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main analysis function\n",
    "    \"\"\"\n",
    "    print(\"ðŸ©º MIT-BIH AF Dataset Analysis Tool\")\n",
    "    print(\"ðŸ“‹ Analyzing dataset composition and single-annotation record impact\\n\")\n",
    "    \n",
    "    # Check if DATA_DIR exists\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        print(f\"âŒ Error: Directory '{DATA_DIR}' not found!\")\n",
    "        print(\"Please update DATA_DIR in the script to point to your dataset location.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Run analysis\n",
    "        single_records, multi_records = analyze_dataset_composition()\n",
    "        \n",
    "        if single_records is not None:\n",
    "            decision = make_inclusion_decision(single_records, multi_records)\n",
    "            save_analysis_results(single_records, multi_records, decision)\n",
    "            \n",
    "            print(f\"\\nðŸŽ‰ Analysis complete!\")\n",
    "            print(f\"ðŸ“„ Check the CSV file for detailed results.\")\n",
    "            print(f\"ðŸ’¡ Use this analysis to inform your preprocessing decisions.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during analysis: {e}\")\n",
    "        print(\"Please check your dataset path and file permissions.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "af",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
